{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import gensim.downloader\n",
    "import src.utils as utils\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "\n",
    "analyzer = MorphAnalyzer()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from src.transform import Normalizer, LengthScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import faiss\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_flat(dim, build_data):\n",
    "    index = faiss.IndexIVFFlat(\n",
    "        faiss.IndexFlatL2(dim), dim, 1024, faiss.METRIC_INNER_PRODUCT\n",
    "    )\n",
    "    index.train(build_data)\n",
    "    index.add(build_data)\n",
    "\n",
    "    return index\n",
    "\n",
    "\n",
    "def search_flat(index, query_data, k):\n",
    "    distances, labels = index.search(query_data, k)\n",
    "    return distances, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"data/jailbreak.json\")\n",
    "normalizer = Normalizer()\n",
    "data[\"jailbreak\"] = normalizer.transform(data.jailbreak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 494)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(1, 2))\n",
    "\n",
    "char_vectorizer.fit_transform(data.jailbreak).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model = gensim.downloader.load('glove-wiki-gigaword-50')\n",
    "# utils.save_model_compressed(w2v_model, \"w2v_model\", 9)\n",
    "\n",
    "w2v_model = utils.load_model(\"w2v_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = w2v_model.key_to_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "etalon = set(string.ascii_lowercase)\n",
    "\n",
    "\n",
    "def in_english(line):\n",
    "    return np.all(np.vectorize(lambda x: x in etalon)(list(line)))\n",
    "\n",
    "\n",
    "corpus = [x for x in corpus if (in_english(x) and x not in stop_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317607"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lscaler = LengthScaler()\n",
    "\n",
    "pipe = Pipeline([(\"vectorizer\", char_vectorizer), (\"lscaler\", lscaler)])\n",
    "\n",
    "X = pipe.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 494)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = pipe.transform([\"dog\", \"transformer\"])\n",
    "\n",
    "dog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = build_flat(494, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_model_compressed(index, \"index.pt\", 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_model(pipe, \"char_grams.pt\")\n",
    "utils.save_model(corpus, \"corpus.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "from typing import Sequence\n",
    "\n",
    "\n",
    "class CorpusSearcher:\n",
    "    def __init__(self):\n",
    "        self.corpus = np.array(utils.load_model(\"corpus.pt\"))\n",
    "        self.vectorizer = utils.load_model(\"char_grams.pt\")\n",
    "        self.index = utils.load_model(\"index2.pt\")\n",
    "\n",
    "    def _find_k_neib(self, data: Sequence[str], k: int = 25) -> Sequence[Sequence[int]]:\n",
    "        data = self.vectorizer.transform(data)\n",
    "        return self.index.search(data, k)[1]\n",
    "\n",
    "    def _best_candidate(self, x, candidates: Sequence[str]):\n",
    "        distances = np.vectorize(lambda y: distance(x, y))(candidates)\n",
    "        idx = np.argmin(distances)\n",
    "        return candidates[idx]\n",
    "\n",
    "    def find(self, data: Sequence[str]):\n",
    "        data = np.array(data)\n",
    "        indexes = self._find_k_neib(data)\n",
    "        result = []\n",
    "        for x, idx in zip(data, indexes):\n",
    "            candidates = self.corpus[idx]\n",
    "            result.append(self._best_candidate(x, candidates))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(\"aaa\", \"bba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.searcher import CorpusSearcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = CorpusSearcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transform', 'doggy']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.find([\"transfrm\", \"dogy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/index.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
